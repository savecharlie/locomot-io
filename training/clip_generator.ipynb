{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ LOCOMOT.IO Clip Generator Pro\n",
    "\n",
    "**Two modes for generating promotional clips:**\n",
    "\n",
    "1. **Discovery Mode** - Runs simulation, ML model learns what's exciting, extracts best moments\n",
    "2. **Director Mode** - Scripts cinematic scenarios (underdog comeback, kill rampage, etc.)\n",
    "\n",
    "Features:\n",
    "- Full game-accurate rendering\n",
    "- Learned excitement scoring (not hardcoded)\n",
    "- Strafe detection (rejects coiling)\n",
    "- Pre-built cinematic scenarios\n",
    "- Exports as MP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pillow imageio imageio-ffmpeg scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from collections import deque\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Dict, Callable\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import Video, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONSTANTS ===\n",
    "WORLD_W, WORLD_H = 100, 75\n",
    "GRID = 16\n",
    "CANVAS_W, CANVAS_H = 640, 480\n",
    "FPS = 30\n",
    "\n",
    "TRAIN_COLORS = [\n",
    "    (255, 0, 255), (0, 170, 255), (255, 85, 85), (255, 200, 0),\n",
    "    (0, 255, 200), (255, 100, 200), (180, 100, 255), (100, 255, 100),\n",
    "]\n",
    "\n",
    "GUN_TYPES = [\n",
    "    {'name': 'PISTOL', 'color': (150, 150, 150)},\n",
    "    {'name': 'SMG', 'color': (100, 200, 255)},\n",
    "    {'name': 'SHOTGUN', 'color': (255, 150, 50)},\n",
    "    {'name': 'LASER', 'color': (255, 0, 255)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN CLASS ===\n",
    "@dataclass\n",
    "class Segment:\n",
    "    x: int\n",
    "    y: int\n",
    "    hp: int = 100\n",
    "    max_hp: int = 100\n",
    "    gun: Optional[Dict] = None\n",
    "\n",
    "@dataclass \n",
    "class Train:\n",
    "    id: int\n",
    "    name: str\n",
    "    segments: List[Segment] = field(default_factory=list)\n",
    "    color: Tuple[int, int, int] = (255, 0, 255)\n",
    "    direction: Tuple[int, int] = (1, 0)\n",
    "    alive: bool = True\n",
    "    kills: int = 0\n",
    "    brain: np.ndarray = None\n",
    "    brain2: np.ndarray = None\n",
    "    is_protagonist: bool = False  # For director mode\n",
    "    script: Optional[Callable] = None  # Custom behavior\n",
    "    direction_history: List[Tuple[int, int]] = field(default_factory=list)\n",
    "    position_history: List[Tuple[int, int]] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.brain is None:\n",
    "            self.brain = np.random.randn(12, 16) * 0.5\n",
    "            self.brain2 = np.random.randn(16, 3) * 0.5\n",
    "    \n",
    "    @property\n",
    "    def head(self): return self.segments[0] if self.segments else None\n",
    "    \n",
    "    @property\n",
    "    def length(self): return len(self.segments)\n",
    "    \n",
    "    def get_vision(self, game) -> np.ndarray:\n",
    "        if not self.head: return np.zeros(12)\n",
    "        vision = []\n",
    "        dirs = [(0,-1), (1,-1), (1,0), (1,1), (0,1), (-1,1), (-1,0), (-1,-1)]\n",
    "        for dx, dy in dirs:\n",
    "            dist, x, y = 0, self.head.x, self.head.y\n",
    "            while dist < 15:\n",
    "                x, y = (x + dx) % WORLD_W, (y + dy) % WORLD_H\n",
    "                dist += 1\n",
    "                if any(seg.x == x and seg.y == y for t in game.trains if t.id != self.id and t.alive for seg in t.segments):\n",
    "                    break\n",
    "            vision.append(1.0 - dist / 15.0)\n",
    "        if game.food:\n",
    "            nf = min(game.food, key=lambda f: abs(f[0]-self.head.x) + abs(f[1]-self.head.y))\n",
    "            vision.extend([(nf[0] - self.head.x) / WORLD_W, (nf[1] - self.head.y) / WORLD_H])\n",
    "        else:\n",
    "            vision.extend([0, 0])\n",
    "        vision.extend([self.direction[0], self.direction[1]])\n",
    "        return np.array(vision)\n",
    "    \n",
    "    def think(self, game) -> int:\n",
    "        if self.script:\n",
    "            return self.script(self, game)\n",
    "        v = self.get_vision(game)\n",
    "        return int(np.argmax(np.tanh(v @ self.brain) @ self.brain2))\n",
    "    \n",
    "    def turn(self, decision: int):\n",
    "        dx, dy = self.direction\n",
    "        if decision == 0: self.direction = (dy, -dx)\n",
    "        elif decision == 2: self.direction = (-dy, dx)\n",
    "        self.direction_history.append(self.direction)\n",
    "        if len(self.direction_history) > 60: self.direction_history.pop(0)\n",
    "    \n",
    "    def move(self):\n",
    "        if not self.alive or not self.head: return\n",
    "        new_x = (self.head.x + self.direction[0]) % WORLD_W\n",
    "        new_y = (self.head.y + self.direction[1]) % WORLD_H\n",
    "        self.position_history.append((new_x, new_y))\n",
    "        if len(self.position_history) > 60: self.position_history.pop(0)\n",
    "        for i in range(len(self.segments) - 1, 0, -1):\n",
    "            self.segments[i].x, self.segments[i].y = self.segments[i-1].x, self.segments[i-1].y\n",
    "        self.head.x, self.head.y = new_x, new_y\n",
    "    \n",
    "    def grow(self, n=1):\n",
    "        for _ in range(n):\n",
    "            t = self.segments[-1]\n",
    "            self.segments.append(Segment(t.x, t.y, gun=random.choice(GUN_TYPES) if random.random()<0.3 else None))\n",
    "    \n",
    "    def is_strafing(self) -> bool:\n",
    "        if len(self.position_history) < 30: return True\n",
    "        s, e = self.position_history[0], self.position_history[-1]\n",
    "        dx = min(abs(e[0]-s[0]), WORLD_W - abs(e[0]-s[0]))\n",
    "        dy = min(abs(e[1]-s[1]), WORLD_H - abs(e[1]-s[1]))\n",
    "        return math.sqrt(dx*dx + dy*dy) > 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXCITEMENT MODEL (Learns what's exciting) ===\n",
    "class ExcitementModel:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(n_estimators=50, max_depth=8)\n",
    "        self.training_data = []  # (features, label)\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def extract_features(self, event: Dict, game_state: Dict) -> np.ndarray:\n",
    "        \"\"\"Extract features from a moment for excitement prediction\"\"\"\n",
    "        return np.array([\n",
    "            event.get('kill', 0),                    # Is this a kill?\n",
    "            event.get('streak', 0),                  # Kill streak count\n",
    "            event.get('length_diff', 0) / 20,        # Size difference (underdog bonus)\n",
    "            event.get('velocity', 0) / 10,           # How fast was killer moving?\n",
    "            event.get('near_miss_count', 0) / 5,     # Close calls in last 2 sec\n",
    "            event.get('trains_nearby', 0) / 5,       # Action density\n",
    "            event.get('killer_health_pct', 1.0),     # Low health = more exciting\n",
    "            event.get('victim_length', 0) / 30,      # Bigger victim = better\n",
    "            event.get('leader_involved', 0),         # Leader in the action?\n",
    "            event.get('comeback', 0),                # Was killer losing before?\n",
    "        ])\n",
    "    \n",
    "    def add_sample(self, features: np.ndarray, excitement: float):\n",
    "        \"\"\"Add a training sample (auto-labeled or human-labeled)\"\"\"\n",
    "        self.training_data.append((features, excitement))\n",
    "    \n",
    "    def auto_label(self, event: Dict) -> float:\n",
    "        \"\"\"Heuristic auto-labeling for initial training\"\"\"\n",
    "        score = 0.0\n",
    "        if event.get('kill'): score += 0.4\n",
    "        score += event.get('streak', 0) * 0.15\n",
    "        score += max(0, -event.get('length_diff', 0)) * 0.02  # Underdog bonus\n",
    "        score += (1 - event.get('killer_health_pct', 1)) * 0.2  # Low health exciting\n",
    "        score += event.get('comeback', 0) * 0.3\n",
    "        score += event.get('near_miss_count', 0) * 0.05\n",
    "        return min(1.0, score)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the model on collected samples\"\"\"\n",
    "        if len(self.training_data) < 20:\n",
    "            print(f\"  Need more data ({len(self.training_data)}/20 samples)\")\n",
    "            return\n",
    "        X = np.array([d[0] for d in self.training_data])\n",
    "        y = np.array([d[1] for d in self.training_data])\n",
    "        self.model.fit(X, y)\n",
    "        self.is_trained = True\n",
    "        print(f\"  âœ… Excitement model trained on {len(self.training_data)} samples\")\n",
    "    \n",
    "    def predict(self, features: np.ndarray) -> float:\n",
    "        \"\"\"Predict excitement score (0-1)\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return self.auto_label({'kill': features[0], 'streak': features[1]*5,\n",
    "                                   'length_diff': features[2]*20, 'killer_health_pct': features[6],\n",
    "                                   'comeback': features[9], 'near_miss_count': features[4]*5})\n",
    "        return float(self.model.predict(features.reshape(1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DIRECTOR MODE (Scripted Scenarios) ===\n",
    "class Director:\n",
    "    \"\"\"Creates scripted cinematic scenarios\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def underdog_comeback(protagonist: Train, game) -> int:\n",
    "        \"\"\"Small train hunts bigger trains aggressively\"\"\"\n",
    "        # Find nearest bigger train\n",
    "        targets = [t for t in game.trains if t.alive and t.id != protagonist.id and t.length > protagonist.length]\n",
    "        if not targets:\n",
    "            targets = [t for t in game.trains if t.alive and t.id != protagonist.id]\n",
    "        if not targets:\n",
    "            return 1  # Go straight\n",
    "        \n",
    "        target = min(targets, key=lambda t: abs(t.head.x - protagonist.head.x) + abs(t.head.y - protagonist.head.y))\n",
    "        return Director._move_toward(protagonist, target.head.x, target.head.y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def kill_rampage(protagonist: Train, game) -> int:\n",
    "        \"\"\"Aggressively hunt any nearby train\"\"\"\n",
    "        targets = [t for t in game.trains if t.alive and t.id != protagonist.id]\n",
    "        if not targets:\n",
    "            return 1\n",
    "        target = min(targets, key=lambda t: abs(t.head.x - protagonist.head.x) + abs(t.head.y - protagonist.head.y))\n",
    "        return Director._move_toward(protagonist, target.head.x, target.head.y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def narrow_escape(protagonist: Train, game) -> int:\n",
    "        \"\"\"Weave through danger, barely surviving\"\"\"\n",
    "        # Find threats and dodge them narrowly\n",
    "        threats = []\n",
    "        for t in game.trains:\n",
    "            if t.alive and t.id != protagonist.id:\n",
    "                for seg in t.segments:\n",
    "                    dist = abs(seg.x - protagonist.head.x) + abs(seg.y - protagonist.head.y)\n",
    "                    if dist < 8:\n",
    "                        threats.append((seg.x, seg.y, dist))\n",
    "        \n",
    "        if not threats:\n",
    "            # No immediate threat - find some action\n",
    "            return Director.kill_rampage(protagonist, game)\n",
    "        \n",
    "        # Dodge but stay close (for excitement)\n",
    "        avg_threat_x = sum(t[0] for t in threats) / len(threats)\n",
    "        avg_threat_y = sum(t[1] for t in threats) / len(threats)\n",
    "        \n",
    "        # Move perpendicular to threat (creates near-miss)\n",
    "        dx = protagonist.head.x - avg_threat_x\n",
    "        dy = protagonist.head.y - avg_threat_y\n",
    "        \n",
    "        # Perpendicular direction\n",
    "        perp_x, perp_y = -dy, dx\n",
    "        target_x = protagonist.head.x + perp_x * 3\n",
    "        target_y = protagonist.head.y + perp_y * 3\n",
    "        \n",
    "        return Director._move_toward(protagonist, target_x, target_y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def leader_dethrone(protagonist: Train, game) -> int:\n",
    "        \"\"\"Hunt the current leader specifically\"\"\"\n",
    "        leader = max((t for t in game.trains if t.alive and t.id != protagonist.id), \n",
    "                    key=lambda t: t.length, default=None)\n",
    "        if not leader:\n",
    "            return 1\n",
    "        return Director._move_toward(protagonist, leader.head.x, leader.head.y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _move_toward(train: Train, target_x: int, target_y: int) -> int:\n",
    "        \"\"\"Return turn decision to move toward target\"\"\"\n",
    "        dx = target_x - train.head.x\n",
    "        dy = target_y - train.head.y\n",
    "        \n",
    "        # Account for wrapping\n",
    "        if abs(dx) > WORLD_W // 2:\n",
    "            dx = -dx\n",
    "        if abs(dy) > WORLD_H // 2:\n",
    "            dy = -dy\n",
    "        \n",
    "        # Current direction\n",
    "        cur_dx, cur_dy = train.direction\n",
    "        \n",
    "        # Calculate angle to target\n",
    "        target_angle = math.atan2(dy, dx)\n",
    "        current_angle = math.atan2(cur_dy, cur_dx)\n",
    "        \n",
    "        diff = target_angle - current_angle\n",
    "        while diff > math.pi: diff -= 2 * math.pi\n",
    "        while diff < -math.pi: diff += 2 * math.pi\n",
    "        \n",
    "        if abs(diff) < 0.3:\n",
    "            return 1  # Straight\n",
    "        elif diff > 0:\n",
    "            return 2  # Right\n",
    "        else:\n",
    "            return 0  # Left\n",
    "\n",
    "# Scenario presets\n",
    "SCENARIOS = {\n",
    "    'underdog_comeback': {\n",
    "        'name': 'Underdog Comeback',\n",
    "        'description': 'Small train defeats giants',\n",
    "        'script': Director.underdog_comeback,\n",
    "        'protagonist_size': 4,  # Start small\n",
    "        'enemy_sizes': [12, 15, 18, 10, 8],  # Big enemies\n",
    "    },\n",
    "    'kill_rampage': {\n",
    "        'name': 'Kill Rampage',\n",
    "        'description': 'Aggressive hunting spree',\n",
    "        'script': Director.kill_rampage,\n",
    "        'protagonist_size': 10,\n",
    "        'enemy_sizes': [6, 7, 8, 5, 6, 7],\n",
    "    },\n",
    "    'narrow_escape': {\n",
    "        'name': 'Narrow Escape',\n",
    "        'description': 'Dodging death repeatedly',\n",
    "        'script': Director.narrow_escape,\n",
    "        'protagonist_size': 8,\n",
    "        'enemy_sizes': [10, 12, 9, 11, 8],\n",
    "    },\n",
    "    'leader_dethrone': {\n",
    "        'name': 'Dethrone the King',\n",
    "        'description': 'Take down the leader',\n",
    "        'script': Director.leader_dethrone,\n",
    "        'protagonist_size': 8,\n",
    "        'enemy_sizes': [20, 6, 7, 5, 6],  # One big leader\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HEADLESS GAME ===\n",
    "class HeadlessGame:\n",
    "    def __init__(self, num_trains: int = 10, scenario: Optional[Dict] = None):\n",
    "        self.trains: List[Train] = []\n",
    "        self.food: List[Tuple[int, int]] = []\n",
    "        self.particles: List[Dict] = []\n",
    "        self.bullets: List[Dict] = []\n",
    "        self.frame = 0\n",
    "        self.events: List[Dict] = []  # For excitement model\n",
    "        self.excitement_model = ExcitementModel()\n",
    "        self.protagonist: Optional[Train] = None\n",
    "        \n",
    "        names = ['Shadow', 'Wolf', 'Blaze', 'Ice', 'Thunder', 'Phoenix', 'Storm', 'Ninja', 'Ghost', 'Viper']\n",
    "        \n",
    "        if scenario:\n",
    "            # Director mode: set up scripted scenario\n",
    "            self._setup_scenario(scenario, names)\n",
    "        else:\n",
    "            # Discovery mode: random setup\n",
    "            for i in range(num_trains):\n",
    "                x, y = random.randint(15, WORLD_W-15), random.randint(15, WORLD_H-15)\n",
    "                train = Train(\n",
    "                    id=i, name=names[i % len(names)] + str(random.randint(10, 99)),\n",
    "                    segments=[Segment(x-j, y, gun=random.choice(GUN_TYPES) if j > 0 and random.random() < 0.4 else None) for j in range(5)],\n",
    "                    color=TRAIN_COLORS[i % len(TRAIN_COLORS)],\n",
    "                    direction=random.choice([(1,0), (-1,0), (0,1), (0,-1)])\n",
    "                )\n",
    "                self.trains.append(train)\n",
    "        \n",
    "        for _ in range(50):\n",
    "            self.food.append((random.randint(0, WORLD_W-1), random.randint(0, WORLD_H-1)))\n",
    "    \n",
    "    def _setup_scenario(self, scenario: Dict, names: List[str]):\n",
    "        \"\"\"Set up a directed scenario\"\"\"\n",
    "        # Create protagonist\n",
    "        x, y = WORLD_W // 2, WORLD_H // 2\n",
    "        size = scenario['protagonist_size']\n",
    "        self.protagonist = Train(\n",
    "            id=0, name='â˜…' + names[0] + 'â˜…',\n",
    "            segments=[Segment(x-j, y, gun=random.choice(GUN_TYPES) if j > 1 else None) for j in range(size)],\n",
    "            color=(0, 255, 100),  # Hero green\n",
    "            direction=(1, 0),\n",
    "            is_protagonist=True,\n",
    "            script=scenario['script']\n",
    "        )\n",
    "        self.trains.append(self.protagonist)\n",
    "        \n",
    "        # Create enemies\n",
    "        for i, enemy_size in enumerate(scenario['enemy_sizes']):\n",
    "            angle = (i / len(scenario['enemy_sizes'])) * 2 * math.pi\n",
    "            dist = 25 + random.randint(-5, 5)\n",
    "            x = int(WORLD_W // 2 + math.cos(angle) * dist) % WORLD_W\n",
    "            y = int(WORLD_H // 2 + math.sin(angle) * dist) % WORLD_H\n",
    "            \n",
    "            train = Train(\n",
    "                id=i+1, name=names[(i+1) % len(names)] + str(random.randint(10, 99)),\n",
    "                segments=[Segment(x-j, y, gun=random.choice(GUN_TYPES) if j > 0 else None) for j in range(enemy_size)],\n",
    "                color=TRAIN_COLORS[(i+1) % len(TRAIN_COLORS)],\n",
    "                direction=random.choice([(1,0), (-1,0), (0,1), (0,-1)])\n",
    "            )\n",
    "            self.trains.append(train)\n",
    "    \n",
    "    def step(self):\n",
    "        self.frame += 1\n",
    "        alive = [t for t in self.trains if t.alive]\n",
    "        \n",
    "        # Track game state for excitement model\n",
    "        game_state = {\n",
    "            'trains_nearby': sum(1 for t in alive for t2 in alive if t.id != t2.id and \n",
    "                                abs(t.head.x - t2.head.x) + abs(t.head.y - t2.head.y) < 15),\n",
    "            'leader': max(alive, key=lambda t: t.length) if alive else None,\n",
    "        }\n",
    "        \n",
    "        for train in alive:\n",
    "            train.turn(train.think(self))\n",
    "            train.move()\n",
    "        \n",
    "        # Food\n",
    "        for train in alive:\n",
    "            for i, (fx, fy) in enumerate(self.food):\n",
    "                if train.head.x == fx and train.head.y == fy:\n",
    "                    train.grow(2)\n",
    "                    self.food.pop(i)\n",
    "                    self.food.append((random.randint(0, WORLD_W-1), random.randint(0, WORLD_H-1)))\n",
    "                    break\n",
    "        \n",
    "        # Collisions\n",
    "        for train in alive:\n",
    "            for other in alive:\n",
    "                if other.id == train.id: continue\n",
    "                for seg in other.segments:\n",
    "                    if train.head.x == seg.x and train.head.y == seg.y:\n",
    "                        if train.length > other.length:\n",
    "                            self._handle_kill(train, other, game_state)\n",
    "                        elif other.length > train.length:\n",
    "                            self._handle_kill(other, train, game_state)\n",
    "                        else:\n",
    "                            train.alive = other.alive = False\n",
    "                            self._add_particles(train)\n",
    "                            self._add_particles(other)\n",
    "                        break\n",
    "                if not train.alive: break\n",
    "        \n",
    "        # Respawn (not protagonist in director mode)\n",
    "        for train in self.trains:\n",
    "            if not train.alive and not train.is_protagonist:\n",
    "                self._respawn(train)\n",
    "        \n",
    "        # Update particles\n",
    "        self.particles = [p for p in self.particles if p['life'] > 0]\n",
    "        for p in self.particles:\n",
    "            p['x'] += p['vx']; p['y'] += p['vy']; p['vy'] += 0.2; p['life'] -= 1\n",
    "    \n",
    "    def _handle_kill(self, killer: Train, victim: Train, game_state: Dict):\n",
    "        \"\"\"Process a kill and record for excitement model\"\"\"\n",
    "        killer.kills += 1\n",
    "        killer.grow(victim.length // 2)\n",
    "        self._add_particles(victim)\n",
    "        victim.alive = False\n",
    "        \n",
    "        # Record event for excitement model\n",
    "        event = {\n",
    "            'frame': self.frame,\n",
    "            'kill': 1,\n",
    "            'streak': killer.kills,\n",
    "            'length_diff': killer.length - victim.length,\n",
    "            'velocity': len([d for d in killer.direction_history[-10:] if d == killer.direction]) if killer.direction_history else 0,\n",
    "            'near_miss_count': 0,  # Could track this\n",
    "            'trains_nearby': game_state['trains_nearby'],\n",
    "            'killer_health_pct': killer.head.hp / killer.head.max_hp if killer.head else 1,\n",
    "            'victim_length': victim.length,\n",
    "            'leader_involved': 1 if (game_state['leader'] and (killer.id == game_state['leader'].id or victim.id == game_state['leader'].id)) else 0,\n",
    "            'comeback': 1 if killer.length < victim.length else 0,\n",
    "            'killer_id': killer.id,\n",
    "            'killer_name': killer.name,\n",
    "            'victim_name': victim.name,\n",
    "            'is_strafing': killer.is_strafing(),\n",
    "        }\n",
    "        \n",
    "        # Auto-label and add to training data\n",
    "        features = self.excitement_model.extract_features(event, game_state)\n",
    "        label = self.excitement_model.auto_label(event)\n",
    "        self.excitement_model.add_sample(features, label)\n",
    "        \n",
    "        event['excitement_score'] = label\n",
    "        event['features'] = features\n",
    "        self.events.append(event)\n",
    "        \n",
    "        emoji = 'ðŸ”¥' if event['streak'] > 1 else 'ðŸ’€'\n",
    "        print(f\"  {emoji} {killer.name} â†’ {victim.name} (excitement: {label:.2f})\")\n",
    "    \n",
    "    def _add_particles(self, train: Train):\n",
    "        for seg in train.segments:\n",
    "            for _ in range(5):\n",
    "                self.particles.append({\n",
    "                    'x': seg.x * GRID + GRID//2, 'y': seg.y * GRID + GRID//2,\n",
    "                    'vx': random.uniform(-4, 4), 'vy': random.uniform(-6, 2),\n",
    "                    'life': random.randint(15, 30), 'color': train.color, 'size': random.randint(2, 5)\n",
    "                })\n",
    "    \n",
    "    def _respawn(self, train: Train):\n",
    "        x, y = random.randint(15, WORLD_W-15), random.randint(15, WORLD_H-15)\n",
    "        train.segments = [Segment(x-j, y) for j in range(4)]\n",
    "        train.direction = random.choice([(1,0), (-1,0), (0,1), (0,-1)])\n",
    "        train.alive = True\n",
    "        train.direction_history.clear()\n",
    "        train.position_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RENDERER ===\n",
    "class GameRenderer:\n",
    "    def dim(self, c, f=0.5): return tuple(int(x*f) for x in c)\n",
    "    \n",
    "    def render(self, game: HeadlessGame, camera_target: Optional[Train] = None) -> Image.Image:\n",
    "        img = Image.new('RGB', (CANVAS_W, CANVAS_H), (17, 17, 17))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        cam_x = (camera_target.head.x * GRID - CANVAS_W // 2) if camera_target and camera_target.head else (WORLD_W * GRID - CANVAS_W) // 2\n",
    "        cam_y = (camera_target.head.y * GRID - CANVAS_H // 2) if camera_target and camera_target.head else (WORLD_H * GRID - CANVAS_H) // 2\n",
    "        \n",
    "        # Grid\n",
    "        for x in range(0, WORLD_W * GRID, GRID):\n",
    "            sx = x - cam_x\n",
    "            if -GRID <= sx < CANVAS_W + GRID:\n",
    "                draw.line([(sx, 0), (sx, CANVAS_H)], fill=(30, 35, 30))\n",
    "        for y in range(0, WORLD_H * GRID, GRID):\n",
    "            sy = y - cam_y\n",
    "            if -GRID <= sy < CANVAS_H + GRID:\n",
    "                draw.line([(0, sy), (CANVAS_W, sy)], fill=(30, 35, 30))\n",
    "        \n",
    "        # Food\n",
    "        for fx, fy in game.food:\n",
    "            sx, sy = fx * GRID - cam_x + GRID//2, fy * GRID - cam_y + GRID//2\n",
    "            if -10 <= sx < CANVAS_W+10 and -10 <= sy < CANVAS_H+10:\n",
    "                draw.ellipse([sx-4, sy-4, sx+4, sy+4], fill=(255, 255, 0))\n",
    "        \n",
    "        # Trains\n",
    "        for train in sorted(game.trains, key=lambda t: t.length):\n",
    "            if not train.alive: continue\n",
    "            for i, seg in enumerate(train.segments):\n",
    "                sx, sy = seg.x * GRID - cam_x, seg.y * GRID - cam_y\n",
    "                if -GRID*2 <= sx < CANVAS_W+GRID*2 and -GRID*2 <= sy < CANVAS_H+GRID*2:\n",
    "                    is_head = (i == 0)\n",
    "                    color = train.color if is_head else self.dim(train.color, 0.6)\n",
    "                    size = GRID - 2 if is_head else GRID - 4\n",
    "                    off = (GRID - size) // 2\n",
    "                    \n",
    "                    if is_head and train.is_protagonist:\n",
    "                        # Glow for protagonist\n",
    "                        draw.ellipse([sx-3, sy-3, sx+GRID+3, sy+GRID+3], fill=self.dim(train.color, 0.3))\n",
    "                    \n",
    "                    draw.rectangle([sx+off, sy+off, sx+off+size, sy+off+size], fill=color)\n",
    "                    \n",
    "                    if seg.gun and not is_head:\n",
    "                        cx, cy = sx + GRID//2, sy + GRID//2\n",
    "                        draw.ellipse([cx-3, cy-3, cx+3, cy+3], fill=seg.gun['color'])\n",
    "                    \n",
    "                    if is_head:\n",
    "                        hp = seg.hp / seg.max_hp\n",
    "                        draw.rectangle([sx+1, sy-4, sx+GRID-1, sy-2], fill=(50,0,0))\n",
    "                        draw.rectangle([sx+1, sy-4, sx+1+int((GRID-2)*hp), sy-2], fill=(0,255,0))\n",
    "        \n",
    "        # Particles\n",
    "        for p in game.particles:\n",
    "            px, py = p['x'] - cam_x, p['y'] - cam_y\n",
    "            if 0 <= px < CANVAS_W and 0 <= py < CANVAS_H:\n",
    "                alpha = p['life'] / 30\n",
    "                draw.ellipse([px-p['size'], py-p['size'], px+p['size'], py+p['size']], \n",
    "                           fill=tuple(int(c*alpha) for c in p['color']))\n",
    "        \n",
    "        # Leaderboard\n",
    "        top = sorted(game.trains, key=lambda t: t.length, reverse=True)[:5]\n",
    "        draw.rectangle([CANVAS_W-140, 5, CANVAS_W-5, 100], fill=(0,0,0), outline=(0,100,0))\n",
    "        for i, t in enumerate(top):\n",
    "            prefix = 'ðŸ‘‘' if i == 0 else f'{i+1}.'\n",
    "            draw.text((CANVAS_W-135, 10+i*18), f\"{prefix} {t.name[:7]}: {t.length}\", fill=t.color)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def save_clip(self, frames: List[Image.Image], filename: str):\n",
    "        with imageio.get_writer(filename, fps=FPS, quality=8, macro_block_size=1) as w:\n",
    "            for f in frames:\n",
    "                w.append_data(np.array(f))\n",
    "        print(f\"  âœ… {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLIP EXTRACTOR ===\n",
    "class ClipExtractor:\n",
    "    def __init__(self, game: HeadlessGame, renderer: GameRenderer):\n",
    "        self.game = game\n",
    "        self.renderer = renderer\n",
    "    \n",
    "    def run(self, frames: int = 4500) -> Dict[int, Image.Image]:\n",
    "        print(f\"ðŸŽ® Running {frames/FPS:.0f}s simulation...\\n\")\n",
    "        all_frames = {}\n",
    "        \n",
    "        for i in range(frames):\n",
    "            self.game.step()\n",
    "            target = self.game.protagonist or max((t for t in self.game.trains if t.alive), key=lambda t: t.length, default=None)\n",
    "            all_frames[self.game.frame] = self.renderer.render(self.game, target)\n",
    "            \n",
    "            if i > 0 and i % 900 == 0:\n",
    "                print(f\"  {i/FPS:.0f}s - {len(self.game.events)} events\")\n",
    "        \n",
    "        # Train excitement model\n",
    "        print(f\"\\nðŸ§  Training excitement model...\")\n",
    "        self.game.excitement_model.train()\n",
    "        \n",
    "        # Re-score events with trained model\n",
    "        for event in self.game.events:\n",
    "            event['learned_score'] = self.game.excitement_model.predict(event['features'])\n",
    "        \n",
    "        return all_frames\n",
    "    \n",
    "    def extract(self, all_frames: Dict, n: int = 5) -> List[Dict]:\n",
    "        # Filter: must be strafing and have good score\n",
    "        valid = [e for e in self.game.events if e.get('is_strafing', True)]\n",
    "        best = sorted(valid, key=lambda e: e.get('learned_score', e['excitement_score']), reverse=True)[:n]\n",
    "        \n",
    "        print(f\"\\nðŸŽ¬ Top {len(best)} clips:\")\n",
    "        clips = []\n",
    "        for i, e in enumerate(best):\n",
    "            start = max(1, e['frame'] - FPS * 3)\n",
    "            end = min(max(all_frames.keys()), e['frame'] + FPS * 4)\n",
    "            clip_frames = [all_frames[f] for f in range(start, end) if f in all_frames]\n",
    "            if len(clip_frames) > FPS * 2:\n",
    "                score = e.get('learned_score', e['excitement_score'])\n",
    "                print(f\"  #{i+1} {e['killer_name']} â†’ {e['victim_name']} (score: {score:.2f})\")\n",
    "                clips.append({'event': e, 'frames': clip_frames, 'rank': i+1})\n",
    "        return clips\n",
    "    \n",
    "    def save(self, clips: List[Dict], outdir: str = 'clips') -> List[str]:\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        print(f\"\\nðŸ’¾ Saving {len(clips)} clips...\")\n",
    "        files = []\n",
    "        for c in clips:\n",
    "            score = c['event'].get('learned_score', c['event']['excitement_score'])\n",
    "            fn = f\"{outdir}/clip_{c['rank']:02d}_{int(score*100)}pts.mp4\"\n",
    "            self.renderer.save_clip(c['frames'], fn)\n",
    "            files.append(fn)\n",
    "        return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ¬ MODE 1: Discovery (ML learns excitement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” DISCOVERY MODE\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ML model learns what makes moments exciting\\n\")\n",
    "\n",
    "game = HeadlessGame(num_trains=10)\n",
    "renderer = GameRenderer()\n",
    "extractor = ClipExtractor(game, renderer)\n",
    "\n",
    "all_frames = extractor.run(frames=FPS * 180)  # 3 minutes\n",
    "clips = extractor.extract(all_frames, n=5)\n",
    "discovery_files = extractor.save(clips, 'discovery_clips')\n",
    "\n",
    "print(f\"\\nðŸŽ‰ {len(discovery_files)} discovery clips saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview discovery clips\n",
    "for f in discovery_files[:2]:\n",
    "    print(f\"\\n{f}\")\n",
    "    display(Video(f, embed=True, width=640))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ¬ MODE 2: Director (Scripted Scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ¬ DIRECTOR MODE\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Available scenarios:\")\n",
    "for key, s in SCENARIOS.items():\n",
    "    print(f\"  â€¢ {key}: {s['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all scenarios\n",
    "director_files = []\n",
    "\n",
    "for scenario_key, scenario in SCENARIOS.items():\n",
    "    print(f\"\\nðŸŽ¬ Filming: {scenario['name']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    game = HeadlessGame(scenario=scenario)\n",
    "    renderer = GameRenderer()\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(FPS * 30):  # 30 sec per scenario\n",
    "        game.step()\n",
    "        if game.protagonist and not game.protagonist.alive:\n",
    "            print(f\"  Protagonist died at {i/FPS:.1f}s\")\n",
    "            break\n",
    "        frames.append(renderer.render(game, game.protagonist))\n",
    "    \n",
    "    if len(frames) > FPS * 5:  # At least 5 seconds\n",
    "        fn = f\"director_clips/{scenario_key}.mp4\"\n",
    "        os.makedirs('director_clips', exist_ok=True)\n",
    "        renderer.save_clip(frames, fn)\n",
    "        director_files.append(fn)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ {len(director_files)} director clips saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview director clips\n",
    "for f in director_files[:2]:\n",
    "    print(f\"\\n{f}\")\n",
    "    display(Video(f, embed=True, width=640))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“¦ Download All Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "all_clips = discovery_files + director_files\n",
    "with zipfile.ZipFile('locomotio_promo_clips.zip', 'w') as z:\n",
    "    for f in all_clips:\n",
    "        z.write(f)\n",
    "\n",
    "print(f\"ðŸ“¦ Downloading {len(all_clips)} clips...\")\n",
    "files.download('locomotio_promo_clips.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
